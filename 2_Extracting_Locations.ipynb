{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db20f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b26e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# essential entity models downloads\n",
    "nltk.downloader.download('maxent_ne_chunker')\n",
    "nltk.downloader.download('words')\n",
    "nltk.downloader.download('treebank')\n",
    "nltk.downloader.download('maxent_treebank_pos_tagger')\n",
    "nltk.downloader.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5051df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locationtagger\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144d1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing sample text\n",
    "sample_text = \"India has very rich and vivid culture\\\n",
    "       widely spread from Kerala to Nagaland to Haryana to Maharashtra. \" \\\n",
    "       \"Delhi being capital with Mumbai financial capital.\\\n",
    "       Can be said better than some western cities such as \" \\\n",
    "       \" Munich, London etc. Pakistan and Bangladesh share its borders. Dhaka is the capital of Bangladesh and Islamabad is the capital \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a8e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting entities.\n",
    "place_entity = locationtagger.find_locations(text = sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30515fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The countries in text : \n",
      "['Bangladesh', 'Pakistan', 'India']\n"
     ]
    }
   ],
   "source": [
    "# getting all countries\n",
    "print(\"The countries in text : \")\n",
    "print(place_entity.countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cacfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The states in text : \n",
      "['Maharashtra', 'Haryana', 'Kerala', 'Nagaland']\n"
     ]
    }
   ],
   "source": [
    "# getting all states\n",
    "print(\"The states in text : \")\n",
    "print(place_entity.regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c43c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cities in text : \n",
      "['Mumbai', 'Delhi', 'London', 'Munich', 'Dhaka', 'Islamabad', 'Haryana']\n"
     ]
    }
   ],
   "source": [
    "# getting all cities\n",
    "print(\"The cities in text : \")\n",
    "print(place_entity.cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae3344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_text = \"India has very rich and vivid culture widely\\\n",
    "        spread from Kerala to Nagaland to Haryana to Maharashtra. \" \\\n",
    "       \"Mumbai being financial capital can be said better\\\n",
    "       than some western cities such as \" \\\n",
    "       \" Lahore, Canberra etc. Pakistan, Afghnistan, Bhutan, Srilanka and Nepal share its borders \\\n",
    "       England, Australia play Cricket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4366f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting entities.\n",
    "place_entity = locationtagger.find_locations(text = another_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9b0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The countries regions in text : \n",
      "{'India': ['Maharashtra', 'Haryana', 'Kerala', 'Nagaland'], 'United Kingdom': ['England']}\n"
     ]
    }
   ],
   "source": [
    "# getting all country regions\n",
    "print(\"The countries regions in text : \")\n",
    "print(place_entity.country_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a35b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The countries cities in text : \n",
      "{'India': ['Mumbai', 'Haryana'], 'Australia': ['Canberra'], 'Pakistan': ['Lahore'], 'United States': ['England']}\n"
     ]
    }
   ],
   "source": [
    "# getting all country cities\n",
    "print(\"The countries cities in text : \")\n",
    "print(place_entity.country_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f671545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All other countries in text : \n",
      "['India', 'United Kingdom', 'Australia', 'Pakistan', 'United States']\n"
     ]
    }
   ],
   "source": [
    "# getting all other countries\n",
    "print(\"All other countries in text : \")\n",
    "print(place_entity.other_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef97a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region cities in text : \n",
      "{'Maharashtra': ['Mumbai'], 'Australian Capital Territory': ['Canberra'], 'Punjab': ['Lahore'], 'Haryana': ['Haryana'], 'Arkansas': ['England']}\n"
     ]
    }
   ],
   "source": [
    "# getting all region cities\n",
    "print(\"The region cities in text : \")\n",
    "print(place_entity.region_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68aefbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All other regions in text : \n",
      "['Maharashtra', 'Australian Capital Territory', 'Punjab', 'Haryana', 'Arkansas']\n"
     ]
    }
   ],
   "source": [
    "# getting all other regions\n",
    "print(\"All other regions in text : \")\n",
    "print(place_entity.other_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a7c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All other entities in text : \n",
      "['Afghnistan', 'Srilanka', 'Cricket']\n"
     ]
    }
   ],
   "source": [
    "# getting all other entities\n",
    "print(\"All other entities in text : \")\n",
    "print(place_entity.other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f707f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa71519",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [\"Hello my name is james\",\n",
    "\"james this is my python notebook\",\n",
    "\"james trying to create a big dataset\",\n",
    "\"james of words to try differnt\",\n",
    "\"features of count vectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f83f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "coun_vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07179b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = coun_vect.fit_transform(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88524568",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd7efccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 1 0 0 1 0 0 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc9a3716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 6,\n",
       " 'james': 7,\n",
       " 'python': 9,\n",
       " 'notebook': 8,\n",
       " 'trying': 11,\n",
       " 'create': 2,\n",
       " 'big': 0,\n",
       " 'dataset': 3,\n",
       " 'words': 13,\n",
       " 'try': 10,\n",
       " 'differnt': 4,\n",
       " 'features': 5,\n",
       " 'count': 1,\n",
       " 'vectorizer': 12}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coun_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7813db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d466c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>big</th>\n",
       "      <th>count</th>\n",
       "      <th>create</th>\n",
       "      <th>dataset</th>\n",
       "      <th>differnt</th>\n",
       "      <th>features</th>\n",
       "      <th>hello</th>\n",
       "      <th>james</th>\n",
       "      <th>notebook</th>\n",
       "      <th>python</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   big  count  create  dataset  differnt  features  hello  james  notebook  \\\n",
       "0    0      0       0        0         0         0      1      1         0   \n",
       "1    0      0       0        0         0         0      0      1         1   \n",
       "2    1      0       1        1         0         0      0      1         0   \n",
       "3    0      0       0        0         1         0      0      1         0   \n",
       "4    0      1       0        0         0         1      0      0         0   \n",
       "\n",
       "   python  try  trying  vectorizer  words  \n",
       "0       0    0       0           0      0  \n",
       "1       1    0       0           0      0  \n",
       "2       0    0       1           0      0  \n",
       "3       0    1       0           0      1  \n",
       "4       0    0       0           1      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a09d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['big',\n",
       " 'count',\n",
       " 'create',\n",
       " 'dataset',\n",
       " 'differnt',\n",
       " 'features',\n",
       " 'hello',\n",
       " 'james',\n",
       " 'notebook',\n",
       " 'python',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'vectorizer',\n",
       " 'words']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coun_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb298080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'count', 'create', 'dataset', 'differnt', 'features', 'hello', 'james', 'notebook', 'python', 'try', 'trying', 'vectorizer', 'words']\n"
     ]
    }
   ],
   "source": [
    "print(coun_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f124b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
